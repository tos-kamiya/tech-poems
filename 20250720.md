ここ数週間くらい、LLMの利用に関してペーパーを見たり、ウェブの記事を見たり、SNSのポストを見たりして、大学教員として思ったのは、

学生のAI利用について、質問丸投げ＆解答丸写しマシーンとして使うようにならないようにガイドしないといけないということ。

現状のAIは、分野にもよるけど、100点満点の解答を出せることはあまりない。小さく閉じた人工的な問題、ベンチマークならともかく、世の中に転がってる複雑に絡んだ状況の一部を見せられて、正しい解答を出せるほどには賢くない。

必然的に、利用者は、AIの解答を手がかりとして、問題や外部の状況を理解し、AIの間違いを修正してインストラクションを与える必要がある。

この問題を理解する助けとしてAIを利用するレベルに達する知識、態度、技術みたいなものを、学生には学んでほしいと思う。

※ 以下はChatGPT 4oさんに英訳してもらったもの。最後の「not just bypass it」を付け足してるところ、賢い

---

Over the past few weeks, I’ve been reading papers, blog posts, and social media threads about how people are using large language models (LLMs). As a university faculty member, one thing has become clear to me:

We need to guide students so that they don’t end up using AI as a machine for dumping in questions and copying out answers.

Current AI systems—depending on the field—rarely produce perfect answers. Unless the task is a narrowly defined artificial benchmark, AI usually can't generate accurate responses when shown only a part of the messy, interconnected problems we face in the real world.

That means users must interpret the AI's response as a clue, refine their understanding of the problem and context, correct the AI’s mistakes, and give better instructions.

I hope students can develop the knowledge, mindset, and skills needed to use AI at this level—as a tool to help them understand the problem, not just bypass it.
