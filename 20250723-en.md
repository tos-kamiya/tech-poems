# Toward a Reconfiguration of the Software Development Process in the Age of AI

## Overview

With the practical application of generative AI—particularly large language models (LLMs)—software development practices are undergoing rapid transformation. This paper proposes a new development process model, arguing that traditional models based on phases such as analysis, design, implementation, and testing are increasingly difficult to apply in co-creative development with LLMs.

The proposed model consists of the following three components:

1. **Prompt-Driven Exploration**
2. **Cognitive Orchestration**
3. **Regenerative Knowledge Architecture**

These components do not represent a fixed sequence of phases; rather, they form a structure where exploration, judgment, and documentation circulate and interact. This paper aims to make these relationships explicit and present a structural understanding of development knowledge in the age of AI.

---

## 1. Background and Problem Setting

Traditional software development models—such as the waterfall or agile models—assume clearly defined specifications, phase separation, and reproducible design and testing.

However, development with LLMs presents unique difficulties:

* **Improvisational Process**
  Boundaries between design, implementation, and testing become blurred, and evaluation and revision of outputs become the primary activity rather than progression according to plan.

* **Non-determinism and Lack of Reproducibility**
  Since outputs vary even for the same prompt, traditional regression testing becomes ineffective, making stable control of deliverables difficult.

* **Difficulty Retaining Context**
  Models cannot retain intent or reasoning over time, necessitating human supplementation.

These challenges conflict with conventional development paradigms based on “controllability” and “reusability,” indicating the need for a new development framework premised on LLM collaboration.

---

## 2. Structure and Positioning of the Proposed Model

Development in collaboration with LLMs is not a linear process based on static blueprints, but a dynamic structure where “generative exploration,” “knowledge structuring,” and “intentional control” interact. This paper defines the following three components:

* **Prompt-Driven Exploration**
  Exploratory interaction where prompts are submitted to the LLM and outputs are evaluated and iterated upon. Development progresses not through planned design, but through evaluation and refinement of generated artifacts.

* **Regenerative Knowledge Architecture**
  External structuring and recording of context and reasoning that the model cannot retain. This supports continuous development and regenerability. Accumulated and updated knowledge forms the foundation for preserving intent and improving the quality of exploration.

* **Cognitive Orchestration**
  Understanding the model's characteristics and output tendencies to guide exploration and make judgments. Human developers evaluate and steer AI outputs to manage the development process.

These three layers are connected as follows:

```
+--------------------------------------------+
|       Cognitive Orchestration              |
|  (Structured judgment, directive generation, orchestration) |
+-------------------+------------------------+
                    | Control based on intent and coherence
                    ▼
+--------------------------------------------+
|   Regenerative Knowledge Architecture      |
|   (Accumulation and update of intent/context for AI and humans) |
+-------------------+------------------------+
                    ▲
      Knowledge structuring from exploration results
                    |
+--------------------------------------------+
|     Prompt-Driven Exploration              |
|     (Generative trial-and-error, prototyping) |
+--------------------------------------------+
```

This structure can be understood as a "spiral process" in which learning through generation and control through knowledge are continuously interwoven. Exploration yields new insights, which are stored as knowledge and guide subsequent exploration. Effective orchestration of the AI depends on knowledge-based judgment.

---

## 3. Strategies and Challenges for Each Component

### Prompt-Driven Exploration

Prompt-Driven Exploration is an exploratory activity in which prompts are exchanged with the LLM to discover potential features and specifications. It dramatically simplifies processes like prototyping and generating alternatives—steps that traditionally required mockups. This enables the concretization of vague requirements and ideas through trial and error over a wide exploratory space.

A key feature is that **reproducibility, consistency, and precision are not prioritized**. Instead, rapid, intuitive evaluation and revision of spontaneous outputs **maximize exploratory freedom and reduce cognitive load for both humans and LLMs**.

However, **minimum traceability is necessary**; unrestricted exploration can hinder integration and reuse. Therefore, outputs and human-LLM interactions should be logged for later use in knowledge structuring and control decisions.

Thus, Prompt-Driven Exploration is not merely a code generation method but serves as a **pre-structural, emergent phase**. Its value lies in expanding the space of potential options and generating materials for design decisions. It creates a co-creative thinking environment where humans and AI collaboratively determine "what to build" and "how to build it."

### Regenerative Knowledge Architecture

Knowledge structuring and recording compensate for the LLM’s inability to retain long-term context and ensure reproducibility and continuity. This component visualizes reasoning, alternatives, and domain knowledge by documenting and organizing them explicitly.

It is crucial that this knowledge **is accessible to both AI and human developers**. LLMs are limited by context window size, and humans by cognitive and temporal constraints. Therefore, the architecture must balance **machine-ingestible brevity** (e.g., prompt templates, code snippets) with **human-readable coherence** (e.g., design memos, narrative documentation).

Designs must integrate various formats and granularities within a **unified knowledge structure** that supports both forms of access.

### Cognitive Orchestration

Effective AI use requires understanding its limitations and outputs and giving appropriate instructions and evaluations. This includes not only prompt design but also setting evaluation criteria, clarifying intent, and determining necessary structural changes (e.g., DB schema redesign, file format redefinition).

Tasks like debugging or test generation tend to rely on **logical, analysis-driven prompt design**, rather than open-ended exploration. Here, understanding and controllability of the model are emphasized over output serendipity.

Thus, Cognitive Orchestration is distinct from Prompt-Driven Exploration and forms the core of **rational, structure-oriented prompt-driven development**.

---

## 4. Future Directions

This model provides a structural framework for organizing new practices of AI-collaborative development. To validate its effectiveness, real-world observation and accumulation of use cases are needed. Possible future directions include:

* **Systematization of development cases** based on this framework
* Analysis of patterns and challenges in each component
* Development of tools and guidelines to support logging and evaluation

Ultimately, the model may enable a meta-level inquiry into the **design of development activities themselves** premised on co-creation with AI.

---

## Appendix A: Characteristics of LLM and Human Intelligence

The following summarizes cognitive differences between LLMs and humans that influence knowledge architecture design:

|                   | Intelligence of LLMs                                      | Human Intelligence                            |
| ----------------- | --------------------------------------------------------- | --------------------------------------------- |
| Constraints       | Context window (thousands to tens of thousands of tokens) | Reading speed, attention span, memory limits  |
| Preferred Formats | JSON, YAML, code, fragmented knowledge                    | Narratives, comparisons, causality            |
| Knowledge Access  | Local attention via tokens                                | Global comprehension and restructuring        |
| Style             | Explicit, structured, short fragments                     | Narrative and diagrammatic for interpretation |
